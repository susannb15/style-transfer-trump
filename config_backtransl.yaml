## Examples will be written here
save_data: data/run/example

## Vocabs
src_vocab: data/vocab.fr
tgt_vocab: data/vocab.en

## Corpus opts
data:
    corpus_1:
        path_src: data/europarl-train.fr
        path_tgt: data/europarl-train.en
    valid:
        path_src: data/europarl-dev.fr
        path_tgt: data/europarl-dev.en

## Train opts
# GPU
world_size: 4
gpu_ranks:
- 0
- 1
- 2
- 3

# specifications
save_model: models/fr-en/fr-en
save_checkpoint_steps: 100 #1000
keep_checkpoint: 10
seed: 42
train_steps: 100000 
valid_steps: 100 #1000

decoder_type: rnn
encoder_type: rnn
word_vec_size: 300
rnn_size: 500
layers: 2
optim: adagrad
learning_rate: 0.15
adagrad_accumulator_init: 0.1
max_grad_norm: 2

batch_size: 4
max_generator_batches: 4
dropout: 0.3

copy_attn: 'false'
global_attention: mlp

## train from checkpoint
#train_from: models/fr-en_step_1000.pt
